{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b81e377-7e0d-48c7-9541-2add27d1a7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, expr, round, when, date_format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58296b5c",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f573745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "spark = SparkSession.builder.master('local').appName('Projeto').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4eb563",
   "metadata": {},
   "source": [
    "#### Carregando dados do PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25045540",
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = create_engine('postgresql://postgres:123456@localhost/king_county')\n",
    "df_pandas = pd.read_sql_query('SELECT * FROM df_king', conexao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b459527",
   "metadata": {},
   "source": [
    "#### Criando um Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e2d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a2677",
   "metadata": {},
   "source": [
    "#### Avaliando os tipos de cada DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a2bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_pandas))\n",
    "print(type(df_spark))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b44f7",
   "metadata": {},
   "source": [
    "#### Renomeando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13adef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "novas_colunas =  ['id', 'data', 'preco', 'quartos', 'banheiros', 'm2_interior', 'm2_espaco_completo', 'numero_andares',\n",
    "                 'vista_orla', 'qualidade_vista', 'qualidade_imovel', 'qualidade_design', 'm2_interior_acima_solo',\n",
    "                 'm2_interior_abaixo_solo', 'ano_construcao', 'ano_ultima_renovacao', 'zipcode', 'lat', 'long',\n",
    "                 'm2_interior_15_vizinhos', 'm2_espaco_completo_15_vizinhos']\n",
    "\n",
    "df_spark = df_spark.toDF(*novas_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9ce10",
   "metadata": {},
   "source": [
    "#### Formatando colunas de ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f384219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ano_construcao', col('ano_construcao').cast('Integer')) \\\n",
    "                               .withColumn('ano_ultima_renovacao', col('ano_ultima_renovacao').cast('Integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0217caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- data: date (nullable = true)\n",
      " |-- preco: double (nullable = true)\n",
      " |-- quartos: double (nullable = true)\n",
      " |-- banheiros: double (nullable = true)\n",
      " |-- m2_interior: double (nullable = true)\n",
      " |-- m2_espaco_completo: double (nullable = true)\n",
      " |-- numero_andares: double (nullable = true)\n",
      " |-- vista_orla: double (nullable = true)\n",
      " |-- qualidade_vista: double (nullable = true)\n",
      " |-- qualidade_imovel: double (nullable = true)\n",
      " |-- qualidade_design: double (nullable = true)\n",
      " |-- m2_interior_acima_solo: double (nullable = true)\n",
      " |-- m2_interior_abaixo_solo: double (nullable = true)\n",
      " |-- ano_construcao: integer (nullable = true)\n",
      " |-- ano_ultima_renovacao: integer (nullable = true)\n",
      " |-- zipcode: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- m2_interior_15_vizinhos: double (nullable = true)\n",
      " |-- m2_espaco_completo_15_vizinhos: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6a2b5",
   "metadata": {},
   "source": [
    "#### Removendo observações com mais de 8 quartos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9af64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes da realizar a filtragem!\n",
      "A quantidade de linhas no DataFrame é de: 21613\n",
      "A quantidade de colunas no DataFrame é de: 21\n"
     ]
    }
   ],
   "source": [
    "print('Antes da realizar a filtragem!')\n",
    "print(f'A quantidade de linhas no DataFrame é de: {df_spark.count()}')\n",
    "print(f'A quantidade de colunas no DataFrame é de: {len(df_spark.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c53535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.where(df_spark.quartos < 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56bea7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após realizar a filtragem!\n",
      "A quantidade de linhas no DataFrame é de: 21602\n",
      "A quantidade de colunas no DataFrame é de: 21\n"
     ]
    }
   ],
   "source": [
    "print('Após realizar a filtragem!')\n",
    "print(f'A quantidade de linhas no DataFrame é de: {df_spark.count()}')\n",
    "print(f'A quantidade de colunas no DataFrame é de: {len(df_spark.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c13ce",
   "metadata": {},
   "source": [
    "#### Criando a coluna de tamanho do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39130b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('tamanho_imovel_completo', round(expr('preco / m2_espaco_completo'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "671781d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|tamanho_imovel_completo|\n",
      "+-----------------------+\n",
      "|                  39.27|\n",
      "|                  74.29|\n",
      "|                   18.0|\n",
      "|                  120.8|\n",
      "+-----------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('tamanho_imovel_completo').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59c7c4",
   "metadata": {},
   "source": [
    "#### Transformando a coluna ano de construção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a1ad40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ano_construcao', when(col('ano_construcao') <= 1925, 1)\n",
    "                               .when((col('ano_construcao') > 1925) & (col('ano_construcao') <= 1950), 2)\n",
    "                               .when((col('ano_construcao') > 1950) & (col('ano_construcao') <= 1975), 3)\n",
    "                               .otherwise(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d21c6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|ano_construcao|\n",
      "+--------------+\n",
      "|             3|\n",
      "|             3|\n",
      "|             2|\n",
      "|             3|\n",
      "+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('ano_construcao').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49d91d",
   "metadata": {},
   "source": [
    "#### Transformando coluna ano da última reforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "166e8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ano_ultima_renovacao', when(col('ano_ultima_renovacao') <= 0, 0)\n",
    "                               .when((col('ano_ultima_renovacao') > 0) & (col('ano_ultima_renovacao') <= 1970), 1)\n",
    "                               .when((col('ano_ultima_renovacao') > 1970) & (col('ano_ultima_renovacao') <= 2000), 2)\n",
    "                               .otherwise(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c16f3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|ano_ultima_renovacao|\n",
      "+--------------------+\n",
      "|                   0|\n",
      "|                   2|\n",
      "|                   0|\n",
      "|                   0|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('ano_ultima_renovacao').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b9805",
   "metadata": {},
   "source": [
    "#### Obtendo coluna com dia da semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5d5321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      data|\n",
      "+----------+\n",
      "|2014-10-13|\n",
      "|2014-12-09|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('data').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb32b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('dia_da_semana', date_format(col('data'), 'EEEE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9b8a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|      data|dia_da_semana|\n",
      "+----------+-------------+\n",
      "|2014-10-13|       Monday|\n",
      "|2014-12-09|      Tuesday|\n",
      "|2015-02-25|    Wednesday|\n",
      "|2014-12-09|      Tuesday|\n",
      "|2015-02-18|    Wednesday|\n",
      "|2014-05-12|       Monday|\n",
      "+----------+-------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['data', 'dia_da_semana']).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfdc940",
   "metadata": {},
   "source": [
    "#### Obtendo dummies das seguintes colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2b23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
