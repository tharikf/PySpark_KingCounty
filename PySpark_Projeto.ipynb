{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b81e377-7e0d-48c7-9541-2add27d1a7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, expr, round, when, date_format, count\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, RobustScaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58296b5c",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ff3e4",
   "metadata": {},
   "source": [
    "#### Iniciando sessão spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f573745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "spark = SparkSession.builder.master('local').appName('Projeto').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4eb563",
   "metadata": {},
   "source": [
    "#### Carregando dados do PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25045540",
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = create_engine('postgresql://postgres:123456@localhost/king_county')\n",
    "df_pandas = pd.read_sql_query('SELECT * FROM df_king', conexao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b459527",
   "metadata": {},
   "source": [
    "#### Criando um Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e2d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a2677",
   "metadata": {},
   "source": [
    "#### Avaliando os tipos de cada DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a2bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_pandas))\n",
    "print(type(df_spark))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b44f7",
   "metadata": {},
   "source": [
    "#### Renomeando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13adef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "novas_colunas =  ['id', 'data', 'preco', 'quartos', 'banheiros', 'm2_interior', 'm2_espaco_completo', 'numero_andares',\n",
    "                 'vista_orla', 'qualidade_vista', 'qualidade_imovel', 'qualidade_design', 'm2_interior_acima_solo',\n",
    "                 'm2_interior_abaixo_solo', 'ano_construcao', 'ano_ultima_renovacao', 'zipcode', 'lat', 'long',\n",
    "                 'm2_interior_15_vizinhos', 'm2_espaco_completo_15_vizinhos']\n",
    "\n",
    "df_spark = df_spark.toDF(*novas_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9ce10",
   "metadata": {},
   "source": [
    "#### Formatando colunas de ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f384219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ano_construcao', col('ano_construcao').cast('Integer')) \\\n",
    "                               .withColumn('ano_ultima_renovacao', col('ano_ultima_renovacao').cast('Integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0217caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- data: date (nullable = true)\n",
      " |-- preco: double (nullable = true)\n",
      " |-- quartos: double (nullable = true)\n",
      " |-- banheiros: double (nullable = true)\n",
      " |-- m2_interior: double (nullable = true)\n",
      " |-- m2_espaco_completo: double (nullable = true)\n",
      " |-- numero_andares: double (nullable = true)\n",
      " |-- vista_orla: double (nullable = true)\n",
      " |-- qualidade_vista: double (nullable = true)\n",
      " |-- qualidade_imovel: double (nullable = true)\n",
      " |-- qualidade_design: double (nullable = true)\n",
      " |-- m2_interior_acima_solo: double (nullable = true)\n",
      " |-- m2_interior_abaixo_solo: double (nullable = true)\n",
      " |-- ano_construcao: integer (nullable = true)\n",
      " |-- ano_ultima_renovacao: integer (nullable = true)\n",
      " |-- zipcode: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- m2_interior_15_vizinhos: double (nullable = true)\n",
      " |-- m2_espaco_completo_15_vizinhos: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa6a2b5",
   "metadata": {},
   "source": [
    "#### Removendo observações com mais de 8 quartos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9af64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes da realizar a filtragem!\n",
      "A quantidade de linhas no DataFrame é de: 21613\n",
      "A quantidade de colunas no DataFrame é de: 21\n"
     ]
    }
   ],
   "source": [
    "print('Antes da realizar a filtragem!')\n",
    "print(f'A quantidade de linhas no DataFrame é de: {df_spark.count()}')\n",
    "print(f'A quantidade de colunas no DataFrame é de: {len(df_spark.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c53535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.where(df_spark.quartos < 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56bea7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após realizar a filtragem!\n",
      "A quantidade de linhas no DataFrame é de: 21602\n",
      "A quantidade de colunas no DataFrame é de: 21\n"
     ]
    }
   ],
   "source": [
    "print('Após realizar a filtragem!')\n",
    "print(f'A quantidade de linhas no DataFrame é de: {df_spark.count()}')\n",
    "print(f'A quantidade de colunas no DataFrame é de: {len(df_spark.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c13ce",
   "metadata": {},
   "source": [
    "#### Criando a coluna de tamanho do imóvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39130b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('tamanho_imovel_completo', round(expr('preco / m2_espaco_completo'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "671781d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|tamanho_imovel_completo|\n",
      "+-----------------------+\n",
      "|                  39.27|\n",
      "|                  74.29|\n",
      "|                   18.0|\n",
      "|                  120.8|\n",
      "+-----------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('tamanho_imovel_completo').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59c7c4",
   "metadata": {},
   "source": [
    "#### Transformando a coluna ano de construção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1ad40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ano_construcao', when(col('ano_construcao') <= 1925, 1)\n",
    "                               .when((col('ano_construcao') > 1925) & (col('ano_construcao') <= 1950), 2)\n",
    "                               .when((col('ano_construcao') > 1950) & (col('ano_construcao') <= 1975), 3)\n",
    "                               .otherwise(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21c6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|ano_construcao|\n",
      "+--------------+\n",
      "|             3|\n",
      "|             3|\n",
      "|             2|\n",
      "|             3|\n",
      "+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('ano_construcao').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcac1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtendo_dummies(spark_dataframe, coluna):\n",
    "    \n",
    "    # Obtendo as categorias de uma coluna\n",
    "    categorias = spark_dataframe.select(coluna).distinct().rdd.flatMap(lambda x : x).collect()\n",
    "    categorias.sort()\n",
    "\n",
    "    # Obtendo as variáveis dummies\n",
    "    df_alterado = spark_dataframe.select('*')\n",
    "\n",
    "    for categoria in categorias:\n",
    "        funcao = udf(lambda item: 1 if item == categoria else 0, IntegerType())\n",
    "        nova_coluna = coluna + '_' + str(categoria).replace('.', '_')\n",
    "        df_alterado = df_alterado.withColumn(nova_coluna, funcao(col(coluna)))\n",
    "        \n",
    "    # Deletando coluna utilizada\n",
    "    df_alterado = df_alterado.drop(coluna)\n",
    "    \n",
    "    return df_alterado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "504b34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = obtendo_dummies(df_spark, 'ano_construcao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39140e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'm2_interior_15_vizinhos',\n",
       " 'm2_espaco_completo_15_vizinhos',\n",
       " 'tamanho_imovel_completo',\n",
       " 'ano_construcao_1',\n",
       " 'ano_construcao_2',\n",
       " 'ano_construcao_3',\n",
       " 'ano_construcao_4']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49d91d",
   "metadata": {},
   "source": [
    "#### Transformando coluna ano da última reforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "166e8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ano_ultima_renovacao', when(col('ano_ultima_renovacao') <= 0, 0)\n",
    "                               .when((col('ano_ultima_renovacao') > 0) & (col('ano_ultima_renovacao') <= 1970), 1)\n",
    "                               .when((col('ano_ultima_renovacao') > 1970) & (col('ano_ultima_renovacao') <= 2000), 2)\n",
    "                               .otherwise(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c16f3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|ano_ultima_renovacao|\n",
      "+--------------------+\n",
      "|                   0|\n",
      "|                   2|\n",
      "|                   0|\n",
      "|                   0|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('ano_ultima_renovacao').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735654cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = obtendo_dummies(df_spark, 'ano_ultima_renovacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0921172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m2_espaco_completo_15_vizinhos',\n",
       " 'tamanho_imovel_completo',\n",
       " 'ano_construcao_1',\n",
       " 'ano_construcao_2',\n",
       " 'ano_construcao_3',\n",
       " 'ano_construcao_4',\n",
       " 'ano_ultima_renovacao_0',\n",
       " 'ano_ultima_renovacao_1',\n",
       " 'ano_ultima_renovacao_2',\n",
       " 'ano_ultima_renovacao_3']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b9805",
   "metadata": {},
   "source": [
    "#### Obtendo coluna com dia da semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5d5321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      data|\n",
      "+----------+\n",
      "|2014-10-13|\n",
      "|2014-12-09|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('data').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb32b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('dia_da_semana', date_format(col('data'), 'EEEE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b8a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|      data|dia_da_semana|\n",
      "+----------+-------------+\n",
      "|2014-10-13|       Monday|\n",
      "|2014-12-09|      Tuesday|\n",
      "|2015-02-25|    Wednesday|\n",
      "|2014-12-09|      Tuesday|\n",
      "|2015-02-18|    Wednesday|\n",
      "|2014-05-12|       Monday|\n",
      "+----------+-------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['data', 'dia_da_semana']).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfdc940",
   "metadata": {},
   "source": [
    "#### Obtendo dummies das seguintes colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d60889ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['qualidade_imovel', 'qualidade_vista', 'dia_da_semana']\n",
    "\n",
    "for item in colunas:\n",
    "    df_spark = obtendo_dummies(df_spark, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82c41979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ano_ultima_renovacao_1',\n",
       " 'ano_ultima_renovacao_2',\n",
       " 'ano_ultima_renovacao_3',\n",
       " 'qualidade_imovel_1_0',\n",
       " 'qualidade_imovel_2_0',\n",
       " 'qualidade_imovel_3_0',\n",
       " 'qualidade_imovel_4_0',\n",
       " 'qualidade_imovel_5_0',\n",
       " 'qualidade_vista_0_0',\n",
       " 'qualidade_vista_1_0',\n",
       " 'qualidade_vista_2_0',\n",
       " 'qualidade_vista_3_0',\n",
       " 'qualidade_vista_4_0',\n",
       " 'dia_da_semana_Friday',\n",
       " 'dia_da_semana_Monday',\n",
       " 'dia_da_semana_Saturday',\n",
       " 'dia_da_semana_Sunday',\n",
       " 'dia_da_semana_Thursday',\n",
       " 'dia_da_semana_Tuesday',\n",
       " 'dia_da_semana_Wednesday']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4971b",
   "metadata": {},
   "source": [
    "#### Removendo colunas que não serão utilizadas na etapa de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86b8f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop('id', 'data', 'm2_interior_acima_solo', 'm2_interior_abaixo_solo',\n",
    "                       'zipcode', 'lat', 'long', 'm2_espaco_completo_15_vizinhos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4837afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preco',\n",
       " 'quartos',\n",
       " 'banheiros',\n",
       " 'm2_interior',\n",
       " 'm2_espaco_completo',\n",
       " 'numero_andares',\n",
       " 'vista_orla',\n",
       " 'qualidade_design',\n",
       " 'm2_interior_15_vizinhos',\n",
       " 'tamanho_imovel_completo']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4748d0",
   "metadata": {},
   "source": [
    "#### Separando em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9797a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df_spark.randomSplit([0.7, 0.3], seed = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce200c9b",
   "metadata": {},
   "source": [
    "#### Verificando o tamanho dos dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a4e90cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho dos dados de treino é: 15106!\n",
      "O tamanho dos dados de teste é: 6496!\n"
     ]
    }
   ],
   "source": [
    "print(f'O tamanho dos dados de treino é: {train_df.count()}!')\n",
    "print(f'O tamanho dos dados de teste é: {test_df.count()}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9c3af",
   "metadata": {},
   "source": [
    "#### Aplicando normalização dos dados com RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c067748",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_norm = ['quartos', 'banheiros', 'm2_interior', 'm2_espaco_completo',\n",
    "                'numero_andares', 'vista_orla', 'qualidade_design', 'm2_interior_15_vizinhos', 'tamanho_imovel_completo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99a815cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicando_robust_scaler(dataframe, lista_colunas):\n",
    "    \n",
    "    # Criando o VectorAssembler para transformar as colunas em vetores\n",
    "    assembler = VectorAssembler(inputCols = lista_colunas, outputCol = \"features\")\n",
    "    \n",
    "    # Criando o RobustScaler para aplicar a escala robusta nas features\n",
    "    scaler = RobustScaler(inputCol = \"features\", outputCol = \"scaled_features\", withScaling = True, withCentering = True)\n",
    "    \n",
    "    # Definindo a pipeline com as etapas de pré-processamento\n",
    "    pipeline = Pipeline(stages = [assembler, scaler])\n",
    "    \n",
    "    # Treinando a pipeline com os dados de treinamento\n",
    "    pipeline_model = pipeline.fit(dataframe)\n",
    "    \n",
    "    # Aplicando a pipeline no DataFrame de entrada\n",
    "    dataframe = pipeline_model.transform(dataframe)\n",
    "    \n",
    "    # Dropando as colunas originais\n",
    "    for coluna in lista_colunas:\n",
    "        dataframe = dataframe.drop(coluna)\n",
    "    \n",
    "    dataframe = dataframe.drop('features')\n",
    "    \n",
    "    # Retornando o DataFrame transformado\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a20088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = aplicando_robust_scaler(train_df, colunas_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4741fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = aplicando_robust_scaler(test_df, colunas_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669cdad",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cf88e",
   "metadata": {},
   "source": [
    "#### Transformando as colunas e o vetor assembler em um só vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71334e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserindo_assembler(dataframe):\n",
    "    \n",
    "    # Listando as colunas e excluindo a coluna target (preco)\n",
    "    colunas = dataframe.columns\n",
    "    colunas = [coluna for coluna in colunas if coluna != 'preco']\n",
    "    \n",
    "    #\n",
    "    assembler = VectorAssembler(inputCols = colunas, outputCol = \"features\")\n",
    "    \n",
    "    #\n",
    "    dataframe = assembler.transform(dataframe)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f102c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = inserindo_assembler(train_df)\n",
    "test_df = inserindo_assembler(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af29a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(fitIntercept = True, featuresCol = 'features', labelCol = 'preco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b37af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80028d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee24ca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 211951.355\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol = 'prediction', labelCol = 'preco', metricName = 'rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f'RMSE: {rmse:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
